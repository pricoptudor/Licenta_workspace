{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Conv1D, MaxPooling1D, \\\n",
    "                            LSTM, LSTMCell, Embedding\n",
    "from tensorflow_addons.seq2seq import BahdanauAttention, TrainingSampler, BasicDecoder\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from muse.Encodings import PianoRollEncoding, PerformanceEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_encoding = PianoRollEncoding(sampling_frequency=4, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_encoding = PerformanceEncoding(time_unit=1/12,\n",
    "                                      velocity_unit=16,\n",
    "                                      use_velocity=True,\n",
    "                                      use_all_off_event=True,\n",
    "                                      use_drum_events=True,\n",
    "                                      use_magenta=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize_velocity:\n",
    "#   mean: 64.25399574283072\n",
    "#   variance: 432.9165195560093\n",
    "  # computed on the training set; ignored by default (unless run() is called with normalize_velocity=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_cnn = Sequential(name='encoder_cnn')\n",
    "encoder_cnn.add(Conv2D(filters=32, \n",
    "                       kernel_size=(12, 12),\n",
    "                       padding='same',\n",
    "                       activation='elu'))\n",
    "encoder_cnn.add(MaxPooling2D(pool_size=(2, 2),\n",
    "                             strides=(2, 2)))\n",
    "encoder_cnn.add(Conv2D(filters=32,\n",
    "                       kernel_size=(4, 4),\n",
    "                       padding='same',\n",
    "                       activation='elu'))\n",
    "encoder_cnn.add(MaxPooling2D(pool_size=(2, 4),\n",
    "                             strides=(2, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_rnn = LSTM(units=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_encoder_cnn = Sequential(name='style_encoder_cnn')\n",
    "style_encoder_cnn.add(Conv1D(filters=300,\n",
    "                             kernel_size=6,\n",
    "                             padding='same',\n",
    "                             activation='elu'))\n",
    "style_encoder_cnn.add(MaxPooling1D(pool_size=2,\n",
    "                                   strides=2))\n",
    "style_encoder_cnn.add(Conv1D(filters=300,\n",
    "                             kernel_size=4,\n",
    "                             padding='same',\n",
    "                             activation='elu'))\n",
    "style_encoder_cnn.add(MaxPooling1D(pool_size=2,\n",
    "                                   strides=2))\n",
    "style_encoder_cnn.add(Conv1D(filters=300,\n",
    "                             kernel_size=4,\n",
    "                             padding='same',\n",
    "                             activation='elu'))\n",
    "style_encoder_cnn.add(MaxPooling1D(pool_size=2,\n",
    "                                   strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_encoder_rnn = LSTM(units=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = BahdanauAttention(units=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = Embedding(output_dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_cell = LSTMCell(units=1024)\n",
    "decoder = BasicDecoder(cell=decoder_cell,\n",
    "                       sampler=TrainingSampler(),\n",
    "                       output_layer=Dense(output_encoding.num_classes),\n",
    "                       maximum_iterations=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_decay = ExponentialDecay(initial_learning_rate=0.001,\n",
    "                            decay_steps=3000,\n",
    "                            decay_rate=0.5)\n",
    "optimizer = Adam(learning_rate=lr_decay)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
